# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hcdkl31ELXGUzLyAG04rJLooAMDw4ZnN

we are going to set upa RAG application with our local allama,to do this we will need to run the models we wantt locally,then run ngrok so thtit can expose it onlineso:
1.ollama pull tinyllama
2. ngrok http 11434
3.isall all other depeneddencies wi:
 !pip instal langchain beautifulsoap4 faiss-cpu
"""

! pip install langchain beautifulsoup4 requests faiss-cpu langchain-text-splitters langchain-community

"""now lets first scrape the website"""

import bs4
from langchain_community.document_loaders import WebBaseLoader

loader=WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
   bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(
            class_=("post-content", "post-title", "post-header")
        )
    ),
)

"""now we load and split the data into chunks for mbedding

"""

from langchain_text_splitters import RecursiveCharacterTextSplitter
data=loader.load()
text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)
chunks=text_splitter.split_documents(data)

"""now we will proceed to store the chunkcs in a vector store of our choice,forthis cas ours is"""